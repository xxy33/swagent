"""
é˜¶æ®µ1æµ‹è¯•ï¼šLLMæ¥å£å±‚æµ‹è¯•

æµ‹è¯•å†…å®¹ï¼š
1. é…ç½®ç³»ç»Ÿ
2. æ—¥å¿—ç³»ç»Ÿ
3. OpenAIå…¼å®¹å®¢æˆ·ç«¯è¿æ¥

ä½¿ç”¨å‰è¯·é…ç½®ï¼š
1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶
2. æ·»åŠ : OPENAI_API_KEY=your_api_key_here
3. å¦‚éœ€ä¿®æ”¹base_urlï¼Œè¯·ä¿®æ”¹config.yamlä¸­çš„llm.providers.openai.base_url
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


async def test_config():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•1: é…ç½®ç³»ç»Ÿ")
    print("=" * 60)

    from swagent.utils.config import get_config

    config = get_config()

    print(f"âœ“ åº”ç”¨åç§°: {config.get('app.name')}")
    print(f"âœ“ åº”ç”¨ç‰ˆæœ¬: {config.get('app.version')}")
    print(f"âœ“ é»˜è®¤LLMæä¾›å•†: {config.get('llm.default_provider')}")

    llm_config = config.get_llm_config()
    print(f"âœ“ LLMæ¨¡å‹: {llm_config.get('default_model')}")
    print(f"âœ“ Base URL: {llm_config.get('base_url')}")
    print(f"âœ“ API Keyå·²é…ç½®: {'æ˜¯' if llm_config.get('api_key') else 'å¦'}")

    return True


async def test_logger():
    """æµ‹è¯•æ—¥å¿—ç³»ç»Ÿ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: æ—¥å¿—ç³»ç»Ÿ")
    print("=" * 60)

    from swagent.utils.logger import get_logger

    logger = get_logger("test")

    logger.debug("è¿™æ˜¯DEBUGæ—¥å¿—")
    logger.info("è¿™æ˜¯INFOæ—¥å¿—")
    logger.warning("è¿™æ˜¯WARNINGæ—¥å¿—")

    print("âœ“ æ—¥å¿—ç³»ç»Ÿå·¥ä½œæ­£å¸¸")

    return True


async def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: LLMè¿æ¥æµ‹è¯•")
    print("=" * 60)

    from swagent.llm.openai_client import OpenAIClient

    try:
        # ä»é…ç½®æ–‡ä»¶åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAIClient.from_config_file()

        print(f"âœ“ å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        print(f"  - æä¾›å•†: {client.provider}")
        print(f"  - æ¨¡å‹: {client.model_name}")
        print(f"  - Base URL: {client.config.base_url}")

        # å‘é€æµ‹è¯•æ¶ˆæ¯
        print("\nå‘é€æµ‹è¯•æ¶ˆæ¯...")
        messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"}
        ]

        response = await client.chat(messages)

        print(f"\nâœ“ LLMå“åº”æˆåŠŸ!")
        print(f"  - æ¨¡å‹: {response.model}")
        print(f"  - Tokenä½¿ç”¨: {response.total_tokens} (è¾“å…¥: {response.prompt_tokens}, è¾“å‡º: {response.completion_tokens})")
        print(f"  - å®ŒæˆåŸå› : {response.finish_reason}")
        print(f"\nå›å¤å†…å®¹:\n{response.content}")

        return True

    except Exception as e:
        print(f"\nâœ— LLMè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        print("\nè¯·æ£€æŸ¥:")
        print("1. .envæ–‡ä»¶ä¸­æ˜¯å¦é…ç½®äº†OPENAI_API_KEY")
        print("2. config.yamlä¸­çš„base_urlæ˜¯å¦æ­£ç¡®")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return False


async def test_llm_stream():
    """æµ‹è¯•æµå¼å“åº”"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: LLMæµå¼å“åº”æµ‹è¯•")
    print("=" * 60)

    from swagent.llm.openai_client import OpenAIClient

    try:
        client = OpenAIClient.from_config_file()

        print("å‘é€æµå¼è¯·æ±‚...")
        messages = [
            {"role": "user", "content": "ç”¨ä¸€å¥è¯è¯´æ˜ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ã€‚"}
        ]

        print("\næµå¼å“åº”å†…å®¹:")
        print("-" * 60)

        full_response = ""
        async for chunk in client.chat_stream(messages):
            print(chunk, end="", flush=True)
            full_response += chunk

        print("\n" + "-" * 60)
        print(f"\nâœ“ æµå¼å“åº”æˆåŠŸ! (å…±{len(full_response)}å­—ç¬¦)")

        return True

    except Exception as e:
        print(f"\nâœ— æµå¼å“åº”æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + " " * 15 + "SWAgent - é˜¶æ®µ1æµ‹è¯•" + " " * 23 + "â•‘")
    print("â•‘" + " " * 20 + "LLMæ¥å£å±‚" + " " * 28 + "â•‘")
    print("â•š" + "â•" * 58 + "â•")

    results = []

    # æµ‹è¯•1: é…ç½®ç³»ç»Ÿ
    try:
        result = await test_config()
        results.append(("é…ç½®ç³»ç»Ÿ", result))
    except Exception as e:
        print(f"\nâœ— é…ç½®ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
        results.append(("é…ç½®ç³»ç»Ÿ", False))

    # æµ‹è¯•2: æ—¥å¿—ç³»ç»Ÿ
    try:
        result = await test_logger()
        results.append(("æ—¥å¿—ç³»ç»Ÿ", result))
    except Exception as e:
        print(f"\nâœ— æ—¥å¿—ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}")
        results.append(("æ—¥å¿—ç³»ç»Ÿ", False))

    # æµ‹è¯•3: LLMè¿æ¥
    try:
        result = await test_llm_connection()
        results.append(("LLMè¿æ¥", result))
    except Exception as e:
        print(f"\nâœ— LLMè¿æ¥æµ‹è¯•å‡ºé”™: {str(e)}")
        results.append(("LLMè¿æ¥", False))

    # æµ‹è¯•4: æµå¼å“åº”ï¼ˆå¯é€‰ï¼‰
    try:
        result = await test_llm_stream()
        results.append(("æµå¼å“åº”", result))
    except Exception as e:
        print(f"\nâœ— æµå¼å“åº”æµ‹è¯•å‡ºé”™: {str(e)}")
        results.append(("æµå¼å“åº”", False))

    # æµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{name}: {status}")

    passed = sum(1 for _, r in results if r)
    total = len(results)

    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ é˜¶æ®µ1æµ‹è¯•å…¨éƒ¨é€šè¿‡! å¯ä»¥ç»§ç»­é˜¶æ®µ2ã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®åé‡è¯•ã€‚")

    print("\n")


if __name__ == "__main__":
    asyncio.run(main())
