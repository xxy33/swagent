"""
äº¤äº’å¼ GIS Agent
åœ¨ç»ˆç«¯ä¸­ä¸ç”¨æˆ·äº¤äº’ï¼Œè‡ªåŠ¨è°ƒç”¨å¤©æ°”æŸ¥è¯¢å’Œå½±åƒåˆ‡ç‰‡å·¥å…·
"""
import asyncio
import os
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from swagent.tools import ToolRegistry
from swagent.tools.domain import WeatherTool, ImageryTool
from swagent.llm import OpenAIClient, LLMConfig
from swagent.utils.logger import get_logger

logger = get_logger(__name__)


class InteractiveGISAgent:
    """äº¤äº’å¼ GIS Agent"""

    def __init__(self):
        self.registry = ToolRegistry()
        self.llm = None
        self.conversation_history = []

    def initialize_llm(self):
        """åˆå§‹åŒ– LLM"""
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        model = os.getenv("DEFAULT_MODEL", "gpt-4")

        if not api_key:
            print("âŒ é”™è¯¯: æœªé…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
            print("  export OPENAI_API_KEY='your-api-key'")
            print("  export OPENAI_BASE_URL='your-base-url'  # å¯é€‰")
            return False

        try:
            config = LLMConfig(
                provider="openai",
                model=model,
                api_key=api_key,
                base_url=base_url,
                temperature=0.7
            )
            self.llm = OpenAIClient(config)
            logger.info(f"LLM åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {model}")
            return True
        except Exception as e:
            print(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def initialize_tools(self):
        """åˆå§‹åŒ–å·¥å…·"""
        try:
            # æ³¨å†Œå·¥å…·
            self.registry.register(WeatherTool())
            self.registry.register(ImageryTool())

            logger.info("å·¥å…·æ³¨å†ŒæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ GIS (åœ°ç†ä¿¡æ¯ç³»ç»Ÿ) åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢å¤©æ°”å’Œè·å–å«æ˜Ÿå½±åƒã€‚

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼š
1. weather_query - æ ¹æ®åæ ‡æŸ¥è¯¢å¤©æ°”æ•°æ®ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ã€é™æ°´ã€é£é€Ÿï¼‰
2. imagery_query - è·å–å«æ˜Ÿå½±åƒï¼ˆGoogle Earthã€å‰æ—ä¸€å·ã€Sentinel-2ï¼‰

ç”¨æˆ·å¯èƒ½ä¼šï¼š
- è¯¢é—®æŸä¸ªåœ°ç‚¹çš„å¤©æ°”
- è¯·æ±‚ä¸‹è½½å«æ˜Ÿå½±åƒ
- è¯¢é—®å¦‚ä½•ä½¿ç”¨è¿™äº›åŠŸèƒ½

é‡è¦æç¤ºï¼š
- å½“ç”¨æˆ·æåˆ°åŸå¸‚åç§°æ—¶ï¼Œä½ éœ€è¦çŸ¥é“å¸¸è§åŸå¸‚çš„å¤§è‡´åæ ‡
- å¯¹äºå¤©æ°”æŸ¥è¯¢ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æ—¶é—´
- å¯¹äºå½±åƒæŸ¥è¯¢ï¼Œé»˜è®¤ä½¿ç”¨ Google Earth æ•°æ®æºï¼Œzoom_level=18
- å¦‚æœç”¨æˆ·è¦ä¿å­˜å½±åƒï¼Œä½¿ç”¨ return_format="file"

å¸¸è§åŸå¸‚åæ ‡å‚è€ƒï¼š
- åŒ—äº¬: (116.4074, 39.9042)
- ä¸Šæµ·: (121.4737, 31.2304)
- å¹¿å·: (113.2644, 23.1291)
- æ·±åœ³: (114.0579, 22.5431)
- æˆéƒ½: (104.0668, 30.5728)
- æ­å·: (120.1551, 30.2741)

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œç®€æ´æ˜äº†ã€‚å½“ä½ éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼Œè¯·æ¸…æ™°è¯´æ˜ä½ åœ¨åšä»€ä¹ˆã€‚"""

    async def call_llm_with_tools(self, user_message: str) -> str:
        """è°ƒç”¨ LLM å¹¶å¤„ç†å·¥å…·è°ƒç”¨"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # å‡†å¤‡æ¶ˆæ¯
        messages = [
            {"role": "system", "content": self.get_system_prompt()},
            *self.conversation_history
        ]

        # è·å–å¯ç”¨å·¥å…·çš„ OpenAI Function æ ¼å¼
        functions = self.registry.to_openai_functions()

        max_iterations = 5  # æœ€å¤šè¿­ä»£æ¬¡æ•°
        iteration = 0

        while iteration < max_iterations:
            iteration += 1

            try:
                # è°ƒç”¨ LLM
                response = await self.llm.chat(
                    messages=messages,
                    functions=functions,
                    temperature=0.7
                )

                # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
                if hasattr(response, 'function_call') and response.function_call:
                    # LLM æƒ³è¦è°ƒç”¨å·¥å…·
                    function_name = response.function_call.name
                    function_args = response.function_call.arguments

                    # è§£æå‚æ•°
                    import json
                    args = json.loads(function_args) if isinstance(function_args, str) else function_args

                    print(f"\nğŸ”§ æ­£åœ¨è°ƒç”¨å·¥å…·: {function_name}")
                    print(f"   å‚æ•°: {args}")

                    # æ‰§è¡Œå·¥å…·
                    result = await self.registry.execute_tool(function_name, **args)

                    if result.success:
                        print(f"âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                    else:
                        print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error}")

                    # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                    messages.append({
                        "role": "assistant",
                        "content": None,
                        "function_call": {
                            "name": function_name,
                            "arguments": function_args
                        }
                    })

                    messages.append({
                        "role": "function",
                        "name": function_name,
                        "content": json.dumps(result.to_dict(), ensure_ascii=False)
                    })

                    # ç»§ç»­å¾ªç¯ï¼Œè®© LLM å¤„ç†å·¥å…·ç»“æœ
                    continue

                else:
                    # LLM ç»™å‡ºäº†æœ€ç»ˆå›å¤
                    assistant_message = response.content if hasattr(response, 'content') else str(response)

                    # æ·»åŠ åˆ°å†å²
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": assistant_message
                    })

                    return assistant_message

            except Exception as e:
                logger.error(f"LLM è°ƒç”¨å‡ºé”™: {e}", exc_info=True)
                return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"

        return "æŠ±æ­‰ï¼Œå¤„ç†è¶…æ—¶ï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„è¯·æ±‚ã€‚"

    async def simple_call_tools(self, user_message: str) -> str:
        """ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è¯†åˆ«æ„å›¾å¹¶è°ƒç”¨å·¥å…·ï¼ˆä¸ä½¿ç”¨ LLM Function Callingï¼‰"""
        message_lower = user_message.lower()

        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        if any(word in message_lower for word in ['å¤©æ°”', 'weather', 'æ¸©åº¦', 'æ°”æ¸©']):
            return await self._handle_weather_query(user_message)
        elif any(word in message_lower for word in ['å½±åƒ', 'å«æ˜Ÿ', 'satellite', 'å›¾ç‰‡', 'ä¸‹è½½']):
            return await self._handle_imagery_query(user_message)
        else:
            return "æˆ‘å¯ä»¥å¸®æ‚¨æŸ¥è¯¢å¤©æ°”æˆ–è·å–å«æ˜Ÿå½±åƒã€‚\nè¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦:\n1. æŸ¥è¯¢æŸä¸ªåœ°ç‚¹çš„å¤©æ°”\n2. ä¸‹è½½æŸä¸ªåœ°ç‚¹çš„å«æ˜Ÿå½±åƒ"

    async def _handle_weather_query(self, message: str) -> str:
        """å¤„ç†å¤©æ°”æŸ¥è¯¢"""
        # ç®€å•çš„åŸå¸‚è¯†åˆ«
        cities = {
            "åŒ—äº¬": (116.4074, 39.9042),
            "ä¸Šæµ·": (121.4737, 31.2304),
            "å¹¿å·": (113.2644, 23.1291),
            "æ·±åœ³": (114.0579, 22.5431),
            "æˆéƒ½": (104.0668, 30.5728),
            "æ­å·": (120.1551, 30.2741),
        }

        found_city = None
        coords = None

        for city, coord in cities.items():
            if city in message:
                found_city = city
                coords = coord
                break

        if not coords:
            return "è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³æŸ¥è¯¢å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿï¼ˆæ”¯æŒï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³ã€æˆéƒ½ã€æ­å·ï¼‰"

        print(f"\nğŸŒ¤ï¸  æ­£åœ¨æŸ¥è¯¢ {found_city} çš„å¤©æ°”...")

        result = await self.registry.execute_tool(
            "weather_query",
            latitude=coords[1],
            longitude=coords[0]
        )

        if result.success:
            data = result.data['data']
            response = f"\nğŸ“ {found_city} å½“å‰å¤©æ°”:\n"
            response += f"   ğŸŒ¡ï¸  æ¸©åº¦: {data.get('temperature_2m')}Â°C\n"
            response += f"   ğŸ’§ æ¹¿åº¦: {data.get('relative_humidity_2m')}%\n"
            response += f"   ğŸŒ§ï¸  é™æ°´: {data.get('precipitation')} mm\n"
            response += f"   ğŸ’¨ é£é€Ÿ: {data.get('wind_speed_10m')} km/h\n"
            response += f"   â° æ—¶é—´: {data.get('time')}"
            return response
        else:
            return f"æŠ±æ­‰ï¼ŒæŸ¥è¯¢å¤©æ°”å¤±è´¥: {result.error}"

    async def _handle_imagery_query(self, message: str) -> str:
        """å¤„ç†å½±åƒæŸ¥è¯¢"""
        cities = {
            "åŒ—äº¬": (116.4074, 39.9042),
            "ä¸Šæµ·": (121.4737, 31.2304),
            "å¹¿å·": (113.2644, 23.1291),
            "æ·±åœ³": (114.0579, 22.5431),
            "æˆéƒ½": (104.0668, 30.5728),
            "æ­å·": (120.1551, 30.2741),
        }

        found_city = None
        coords = None

        for city, coord in cities.items():
            if city in message:
                found_city = city
                coords = coord
                break

        if not coords:
            return "è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³ä¸‹è½½å“ªä¸ªåŸå¸‚çš„å«æ˜Ÿå½±åƒï¼Ÿï¼ˆæ”¯æŒï¼šåŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³ã€æˆéƒ½ã€æ­å·ï¼‰"

        # æ£€æŸ¥æ˜¯å¦è¦ä¿å­˜åˆ°æ–‡ä»¶
        save_to_file = any(word in message for word in ['ä¸‹è½½', 'ä¿å­˜', 'æ–‡ä»¶', 'save', 'download'])

        print(f"\nğŸ›°ï¸  æ­£åœ¨è·å– {found_city} çš„å«æ˜Ÿå½±åƒ...")

        params = {
            "location": [coords[0], coords[1]],
            "source": "google",
            "zoom_level": 18,
            "point_size": 1000
        }

        if save_to_file:
            params["return_format"] = "file"
            params["output_path"] = "./satellite_images"
            params["filename"] = f"{found_city}_satellite.png"

        result = await self.registry.execute_tool("imagery_query", **params)

        if result.success:
            data = result.data
            response = f"\nğŸ“ {found_city} å«æ˜Ÿå½±åƒ:\n"
            response += f"   ğŸ—ºï¸  æ•°æ®æº: {data.get('source')}\n"
            response += f"   ğŸ“ å½±åƒå°ºå¯¸: {data.get('shape')[0]}x{data.get('shape')[1]} åƒç´ \n"

            if save_to_file and 'saved_path' in data:
                response += f"   ğŸ’¾ å·²ä¿å­˜åˆ°: {data.get('saved_path')}\n"
                response += f"   ğŸ“„ æ–‡ä»¶å: {data.get('filename')}"
            else:
                response += f"   ğŸ“Š æ•°æ®å·²è·å–ï¼Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç†"

            return response
        else:
            return f"æŠ±æ­‰ï¼Œè·å–å½±åƒå¤±è´¥: {result.error}"

    def print_welcome(self):
        """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸŒ äº¤äº’å¼ GIS Agent")
        print("="*60)
        print("\nåŠŸèƒ½:")
        print("  1. ğŸŒ¤ï¸  å¤©æ°”æŸ¥è¯¢ - æŸ¥è¯¢åŸå¸‚çš„å®æ—¶å¤©æ°”")
        print("  2. ğŸ›°ï¸  å«æ˜Ÿå½±åƒ - è·å–/ä¸‹è½½å«æ˜Ÿå›¾ç‰‡")
        print("\næ”¯æŒçš„åŸå¸‚:")
        print("  åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³ã€æˆéƒ½ã€æ­å·")
        print("\nå‘½ä»¤:")
        print("  help  - æ˜¾ç¤ºå¸®åŠ©")
        print("  quit  - é€€å‡ºç¨‹åº")
        print("  clear - æ¸…ç©ºå¯¹è¯å†å²")
        print("\n" + "="*60)
        print()

    def print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“– ä½¿ç”¨å¸®åŠ©")
        print("="*60)
        print("\nç¤ºä¾‹:")
        print("  â€¢ æŸ¥è¯¢åŒ—äº¬çš„å¤©æ°”")
        print("  â€¢ ä¸‹è½½ä¸Šæµ·çš„å«æ˜Ÿå½±åƒ")
        print("  â€¢ æ·±åœ³ç°åœ¨æ¸©åº¦å¤šå°‘")
        print("  â€¢ è·å–å¹¿å·çš„å«æ˜Ÿå›¾ç‰‡å¹¶ä¿å­˜")
        print("\næç¤º:")
        print("  - ç›´æ¥ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨çš„éœ€æ±‚")
        print("  - æ”¯æŒå…³é”®è¯: å¤©æ°”ã€æ¸©åº¦ã€å½±åƒã€å«æ˜Ÿã€ä¸‹è½½ç­‰")
        print("  - æåˆ°'ä¸‹è½½'æˆ–'ä¿å­˜'ä¼šè‡ªåŠ¨ä¿å­˜å½±åƒåˆ°æœ¬åœ°")
        print("="*60 + "\n")

    async def run(self):
        """è¿è¡Œäº¤äº’å¼ä¼šè¯"""
        self.print_welcome()

        # åˆå§‹åŒ–
        print("æ­£åœ¨åˆå§‹åŒ–...")

        if not self.initialize_tools():
            return

        print("âœ… å·¥å…·åˆå§‹åŒ–æˆåŠŸ")

        # å°è¯•åˆå§‹åŒ– LLMï¼ˆå¯é€‰ï¼‰
        llm_available = self.initialize_llm()

        if llm_available:
            print("âœ… LLM åˆå§‹åŒ–æˆåŠŸ - ä½¿ç”¨æ™ºèƒ½æ¨¡å¼")
            use_llm = True
        else:
            print("âš ï¸  ä½¿ç”¨ç®€åŒ–æ¨¡å¼ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰")
            print("æç¤º: é…ç½® OPENAI_API_KEY å¯å¯ç”¨æ™ºèƒ½å¯¹è¯\n")
            use_llm = False

        print("\nå¼€å§‹å¯¹è¯... (è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©, 'quit' é€€å‡º)\n")

        # ä¸»å¾ªç¯
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("ğŸ‘¤ æ‚¨: ").strip()

                if not user_input:
                    continue

                # å¤„ç†å‘½ä»¤
                if user_input.lower() == 'quit':
                    print("\nğŸ‘‹ å†è§ï¼")
                    break

                if user_input.lower() == 'help':
                    self.print_help()
                    continue

                if user_input.lower() == 'clear':
                    self.conversation_history = []
                    print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º\n")
                    continue

                # å¤„ç†ç”¨æˆ·è¯·æ±‚
                print()  # ç©ºè¡Œ

                if use_llm:
                    response = await self.call_llm_with_tools(user_input)
                else:
                    response = await self.simple_call_tools(user_input)

                print(f"\nğŸ¤– Agent: {response}\n")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}\n")
                logger.error(f"é”™è¯¯: {e}", exc_info=True)


async def main():
    """ä¸»å‡½æ•°"""
    agent = InteractiveGISAgent()
    await agent.run()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²ç»ˆæ­¢")
